name: Run FPL Engine

on:
  workflow_dispatch:
  schedule:
    - cron: "0 8 * * FRI"

jobs:
  run-engine:
    runs-on: ubuntu-latest

    steps:
      # -------------------------------------------------------
      # 1. Checkout repo
      # -------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4

      # -------------------------------------------------------
      # 2. Set up Python
      # -------------------------------------------------------
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # -------------------------------------------------------
      # 3. Install dependencies
      # -------------------------------------------------------
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # -------------------------------------------------------
      # 4. Fetch and parse FBref xG/xA (robust HTML → CSV)
      # -------------------------------------------------------
      - name: Download FBref HTML
        run: |
          mkdir -p data
          curl -L "https://fbref.com/en/comps/9/Premier-League-Stats" \
            -H "User-Agent: Mozilla/5.0" \
            -o data/fbref.html

      - name: Extract xG/xA from FBref HTML (robust)
        run: |
          python - << 'EOF'
          import pandas as pd
          import numpy as np

          TEAM_MAP = {
              "Arsenal": "ARS",
              "Aston Villa": "AVL",
              "Bournemouth": "BOU",
              "Brentford": "BRE",
              "Brighton": "BHA",
              "Chelsea": "CHE",
              "Crystal Palace": "CRY",
              "Everton": "EVE",
              "Fulham": "FUL",
              "Liverpool": "LIV",
              "Luton Town": "LUT",
              "Manchester City": "MCI",
              "Manchester Utd": "MUN",
              "Newcastle Utd": "NEW",
              "Nottingham Forest": "NFO",
              "Sheffield Utd": "SHU",
              "Tottenham": "TOT",
              "West Ham": "WHU",
              "Wolverhampton Wanderers": "WOL",
          }

          def normalize_name(s):
              return (
                  str(s)
                  .lower()
                  .replace("-", " ")
                  .replace("’", "'")
                  .replace("`", "'")
                  .strip()
              )

          try:
              tables = pd.read_html("data/fbref.html")
              print(f"[DEBUG] Loaded {len(tables)} tables from FBref.")

              candidate = None
              for i, t in enumerate(tables):
                  cols = [c.lower().strip() for c in t.columns]
                  if any("xg" in c for c in cols) and any("xa" in c for c in cols):
                      print(f"[DEBUG] Found candidate xG table at index {i}.")
                      candidate = t.copy()
                      break

              if candidate is None:
                  raise Exception("No table with xG/xA found in FBref page")

              df = candidate
              df.columns = [c.lower().strip() for c in df.columns]

              # Identify minutes column
              if "minutes" in df.columns:
                  minutes_col = "minutes"
              elif "min" in df.columns:
                  minutes_col = "min"
              elif "90s" in df.columns:
                  minutes_col = "90s"
              else:
                  raise Exception("Could not find minutes/min/90s column")

              minutes = pd.to_numeric(df[minutes_col], errors="coerce").fillna(0)
              if minutes_col == "90s":
                  minutes = minutes * 90

              # Identify xG/xA columns
              def find_col(candidates):
                  for cand in candidates:
                      if cand in df.columns:
                          return cand
                  return None

              xg_col = find_col(["xg", "expected", "npxg"])
              xa_col = find_col(["xa", "assisted", "xag", "xg assisted"])

              if xg_col is None or xa_col is None:
                  raise Exception(f"Could not find xg/xa columns; xg={xg_col}, xa={xa_col}")

              # Normalize player and squad names
              df["player"] = (
                  df["player"]
                  .astype(str)
                  .str.replace(r"\s+", " ", regex=True)
                  .str.strip()
              )

              df["team_short"] = df["squad"].map(TEAM_MAP).fillna(df["squad"])

              # Build final output
              out = pd.DataFrame({
                  "web_name": df["player"],
                  "team_short": df["team_short"],
                  "xg": pd.to_numeric(df[xg_col], errors="coerce").fillna(0),
                  "xa": pd.to_numeric(df[xa_col], errors="coerce").fillna(0),
                  "minutes": minutes,
              })

              out.to_csv("xg_xa_latest.csv", index=False)
              print(f"[SUCCESS] Created xg_xa_latest.csv with {len(out)} rows.")

          except Exception as e:
              print("[ERROR] FBref xG extraction failed:", e)
              print("[DEBUG] Writing empty fallback CSV.")
              pd.DataFrame(
                  {"web_name": [], "team_short": [], "xg": [], "xa": [], "minutes": []}
              ).to_csv("xg_xa_latest.csv", index=False)

          EOF
      # -------------------------------------------------------
      # 5. Run engine
      # -------------------------------------------------------
      - name: Run FPL engine
        run: python engine_gw13.py

      # -------------------------------------------------------
      # 6. Generate plain-text summary for email (pure Python)
      # -------------------------------------------------------
      - name: Build email summary
        id: summary
        run: |
          python - << 'EOF'
          import glob
          import os
          from pathlib import Path

          import pandas as pd

          lines = ["FPL Engine Summary", ""]

          # Captain suggestion
          myteam_files = glob.glob("gw*_predictions_myteam.csv")
          if myteam_files:
              df = pd.read_csv(myteam_files[0])
              if "multi_gw_points" in df.columns:
                  df = df.sort_values("multi_gw_points", ascending=False)
                  top = df.iloc[0]
                  lines.append(
                      f"Suggested Captain: {top.web_name} ({top.team_short}) — {top.multi_gw_points:.2f} pts"
                  )
                  lines.append("")
              else:
                  lines.append("Captain suggestion unavailable (multi_gw_points missing).")
                  lines.append("")

          # Single-transfer suggestion
          single_files = glob.glob("gw*_transfer_suggestions.csv")
          if single_files:
              df = pd.read_csv(single_files[0])
              if not df.empty:
                  top = df.iloc[0]
                  lines.append("Top Single Transfer:")
                  lines.append(
                      f"Sell {top.sell_name} → Buy {top.buy_name} (Gain: {top.gain:.2f})"
                  )
                  lines.append("")

          # Double-transfer suggestion
          double_files = glob.glob("gw*_double_transfers.csv")
          if double_files:
              df = pd.read_csv(double_files[0])
              if not df.empty:
                  top = df.iloc[0]
                  lines.append("Top Double Transfer:")
                  lines.append(
                      f"Sell {top.sell1} & {top.sell2} → Buy {top.buy1} & {top.buy2} (Net Gain: {top.net_gain:.2f})"
                  )
                  lines.append("")

          summary_text = "\n".join(lines)

          # Write to file for debugging
          Path("summary.txt").write_text(summary_text, encoding="utf-8")

          # Expose via GITHUB_OUTPUT
          gh_out = os.environ.get("GITHUB_OUTPUT")
          if gh_out:
              with open(gh_out, "a", encoding="utf-8") as f:
                  print("summary_out<<EOF", file=f)
                  f.write(summary_text + "\n")
                  print("EOF", file=f)

          print(summary_text)
          EOF

      # -------------------------------------------------------
      # 7. ZIP outputs
      # -------------------------------------------------------
      - name: Zip outputs
        run: |
          mkdir -p artifacts
          zip artifacts/fpl-engine-csvs.zip *.csv

      # -------------------------------------------------------
      # 8. Upload artifacts
      # -------------------------------------------------------
      - name: Upload CSV artifacts
        uses: actions/upload-artifact@v4
        with:
          name: fpl-engine-csvs
          path: artifacts/fpl-engine-csvs.zip

      # -------------------------------------------------------
      # 9. Email results
      # -------------------------------------------------------
      - name: Email results
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          secure: starttls
          username: ${{ secrets.SMTP_USERNAME }}
          password: ${{ secrets.SMTP_PASSWORD }}
          from: ${{ secrets.EMAIL_FROM }}
          to: ${{ secrets.EMAIL_TO }}
          subject: "FPL Engine Results (Run #${{ github.run_number }})"
          body: |
            Your FPL engine run has completed.

            =============================
            FPL SUMMARY
            =============================

            ${{ steps.summary.outputs.summary_out }}

            -----------------------------
            Full run details:
            ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

            CSV outputs are attached.
          attachments: artifacts/fpl-engine-csvs.zip
